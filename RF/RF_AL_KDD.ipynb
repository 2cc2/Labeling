{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelled Data Shape: (4940, 42)\n",
      "Unlabelled Data Shape: (3111, 41)\n",
      "Except Data Shape: (4940, 42)\n",
      "X_train Labelled Shape: (49, 41)\n",
      "y_train Labelled Shape: (49,)\n",
      "X_test Shape: (4891, 41)\n",
      "y_test Shape: (4891,)\n",
      "X_except Shape: (4940, 41)\n",
      "y_except Shape: (4940,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "\n",
    "# 忽略特定的 UserWarning 警告\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from current font.\")\n",
    "\n",
    "# 替换为实际数据集路径\n",
    "labelled_data_path = 'kddcup_1_percent'\n",
    "unlabelled_data_path = 'kddcup_1_percent.unlabeled'\n",
    "except_path = 'kddcup_1_percent'\n",
    "\n",
    "# 读取有标签的数据集\n",
    "df_labelled = pd.read_csv(labelled_data_path, header=None)\n",
    "\n",
    "# 读取无标签的数据集\n",
    "df_unlabelled = pd.read_csv(unlabelled_data_path, header=None)\n",
    "df_except = pd.read_csv(except_path, header=None)\n",
    "\n",
    "# 定义列名\n",
    "columns = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \n",
    "           \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \n",
    "           \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \n",
    "           \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \n",
    "           \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \n",
    "           \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \n",
    "           \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \n",
    "           \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \n",
    "           \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \n",
    "           \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \n",
    "           \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \n",
    "           \"dst_host_srv_rerror_rate\", \"label\"]\n",
    "\n",
    "df_labelled.columns = columns\n",
    "df_unlabelled.columns = columns[:-1]  # 无标签数据集没有label列\n",
    "df_except.columns = columns\n",
    "\n",
    "# 获取分类特征的所有种类\n",
    "categorical_columns = [\"protocol_type\", \"service\", \"flag\"]\n",
    "\n",
    "# 为所有分类特征创建一个LabelEncoder对象\n",
    "le_dict = {col: LabelEncoder() for col in categorical_columns}\n",
    "\n",
    "# Fit LabelEncoder对象于有标签和无标签数据集中\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    le.fit(pd.concat([df_labelled[col], df_unlabelled[col], df_except[col]]))\n",
    "\n",
    "# 对有标签数据集进行编码\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    df_labelled[col] = le.transform(df_labelled[col])\n",
    "\n",
    "# 对无标签数据集进行编码\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    df_unlabelled[col] = le.transform(df_unlabelled[col])\n",
    "\n",
    "# 对df_except进行编码\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    df_except[col] = le.transform(df_except[col])\n",
    "\n",
    "# 将标签编码\n",
    "df_labelled['label'] = df_labelled['label'].apply(lambda x: 1 if x != 'normal.' else 0)\n",
    "df_except['label'] = df_except['label'].apply(lambda x: 1 if x != 'normal.' else 0)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "df_labelled[df_labelled.columns[:-1]] = scaler.fit_transform(df_labelled[df_labelled.columns[:-1]])\n",
    "df_unlabelled[df_unlabelled.columns] = scaler.transform(df_unlabelled[df_unlabelled.columns])\n",
    "df_except[df_except.columns[:-1]] = scaler.transform(df_except[df_except.columns[:-1]])\n",
    "\n",
    "# 划分有标签数据集的训练集和测试集\n",
    "X = df_labelled.drop(columns=['label'])\n",
    "y = df_labelled['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.99, random_state=42)\n",
    "\n",
    "# 使用训练集中所有的有标签数据\n",
    "X_train_labelled = X_train\n",
    "y_train_labelled = y_train\n",
    "\n",
    "# 无标签数据\n",
    "X_train_unlabelled = df_unlabelled\n",
    "\n",
    "# 处理后的df_except\n",
    "X_except = df_except.drop(columns=['label'])\n",
    "y_except = df_except['label']\n",
    "\n",
    "# 显示数据集状态\n",
    "print(f\"Labelled Data Shape: {df_labelled.shape}\")\n",
    "print(f\"Unlabelled Data Shape: {df_unlabelled.shape}\")\n",
    "print(f\"Except Data Shape: {df_except.shape}\")\n",
    "\n",
    "# 显示分割后数据集的形状\n",
    "print(f\"X_train Labelled Shape: {X_train_labelled.shape}\")\n",
    "print(f\"y_train Labelled Shape: {y_train_labelled.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")\n",
    "print(f\"X_except Shape: {X_except.shape}\")\n",
    "print(f\"y_except Shape: {y_except.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only found 0 labels for query samples.\n",
      "Accuracy: 0.9748517685544879\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93       960\n",
      "           1       0.97      1.00      0.98      3931\n",
      "\n",
      "    accuracy                           0.97      4891\n",
      "   macro avg       0.98      0.94      0.96      4891\n",
      "weighted avg       0.98      0.97      0.97      4891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 初始模型训练\n",
    "clf = SVC(probability=True, random_state=42)\n",
    "clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "# 主动学习迭代\n",
    "max_iterations = 10\n",
    "n_queries = 10  # 每次迭代查询的样本数\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    # 如果无标签数据为空，则停止迭代\n",
    "    if len(X_train_unlabelled) == 0:\n",
    "        break\n",
    "    \n",
    "    # 使用模型预测无标签数据的概率\n",
    "    y_unlabelled_proba = clf.predict_proba(X_train_unlabelled)\n",
    "    \n",
    "    # 计算不确定性 - 这里使用预测概率最接近0.5的样本\n",
    "    uncertainty_index = np.argsort(np.abs(y_unlabelled_proba[:, 1] - 0.5))[:n_queries]\n",
    "    \n",
    "    # 选择不确定性最高的样本\n",
    "    X_query = X_train_unlabelled.iloc[uncertainty_index]\n",
    "    \n",
    "    # 从df_except中获取标签\n",
    "    X_query_features = X_query.reset_index(drop=True)\n",
    "    y_query_labels = df_except[df_except.drop(columns=['label']).apply(tuple, axis=1).isin(X_query_features.apply(tuple, axis=1))]['label'].values\n",
    "    \n",
    "    # 检查是否找到了所有查询样本的标签\n",
    "    if len(y_query_labels) < n_queries:\n",
    "        print(f\"Warning: Only found {len(y_query_labels)} labels for query samples.\")\n",
    "        n_queries = len(y_query_labels)\n",
    "        X_query = X_query.iloc[:n_queries]\n",
    "    \n",
    "    # 将查询到的样本及其标签添加到有标签数据集中\n",
    "    X_train_labelled = pd.concat([X_train_labelled, X_query])\n",
    "    y_train_labelled = pd.concat([y_train_labelled, pd.Series(y_query_labels)])\n",
    "    \n",
    "    # 从无标签数据集中删除查询到的样本\n",
    "    X_train_unlabelled = X_train_unlabelled.drop(X_query.index)\n",
    "    \n",
    "    # 重新训练模型\n",
    "    clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "# 模型评估\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
