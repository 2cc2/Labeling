{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelled Data Shape: (4940, 42)\n",
      "Unlabelled Data Shape: (3111, 41)\n",
      "Except Data Shape: (4940, 42)\n",
      "X_train Labelled Shape: (3952, 41)\n",
      "y_train Labelled Shape: (3952,)\n",
      "X_test Shape: (988, 41)\n",
      "y_test Shape: (988,)\n",
      "X_except Shape: (4940, 41)\n",
      "y_except Shape: (4940,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "\n",
    "# 忽略特定的 UserWarning 警告\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from current font.\")\n",
    "\n",
    "# 替换为实际数据集路径\n",
    "labelled_data_path = 'kddcup_1_percent'\n",
    "unlabelled_data_path = 'kddcup_1_percent.unlabeled'\n",
    "except_path = 'kddcup_1_percent'\n",
    "\n",
    "# 读取有标签的数据集\n",
    "df_labelled = pd.read_csv(labelled_data_path, header=None)\n",
    "\n",
    "# 读取无标签的数据集\n",
    "df_unlabelled = pd.read_csv(unlabelled_data_path, header=None)\n",
    "df_except = pd.read_csv(except_path, header=None)\n",
    "\n",
    "# 定义列名\n",
    "columns = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \n",
    "           \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \n",
    "           \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \n",
    "           \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \n",
    "           \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\", \"count\", \n",
    "           \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \n",
    "           \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \n",
    "           \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \n",
    "           \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \n",
    "           \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \n",
    "           \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \n",
    "           \"dst_host_srv_rerror_rate\", \"label\"]\n",
    "\n",
    "df_labelled.columns = columns\n",
    "df_unlabelled.columns = columns[:-1]  # 无标签数据集没有label列\n",
    "df_except.columns = columns\n",
    "\n",
    "# 获取分类特征的所有种类\n",
    "categorical_columns = [\"protocol_type\", \"service\", \"flag\"]\n",
    "\n",
    "# 为所有分类特征创建一个LabelEncoder对象\n",
    "le_dict = {col: LabelEncoder() for col in categorical_columns}\n",
    "\n",
    "# Fit LabelEncoder对象于有标签和无标签数据集中\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    le.fit(pd.concat([df_labelled[col], df_unlabelled[col], df_except[col]]))\n",
    "\n",
    "# 对有标签数据集进行编码\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    df_labelled[col] = le.transform(df_labelled[col])\n",
    "\n",
    "# 对无标签数据集进行编码\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    df_unlabelled[col] = le.transform(df_unlabelled[col])\n",
    "\n",
    "# 对df_except进行编码\n",
    "for col in categorical_columns:\n",
    "    le = le_dict[col]\n",
    "    df_except[col] = le.transform(df_except[col])\n",
    "\n",
    "# 将标签编码\n",
    "df_labelled['label'] = df_labelled['label'].apply(lambda x: 1 if x != 'normal.' else 0)\n",
    "df_except['label'] = df_except['label'].apply(lambda x: 1 if x != 'normal.' else 0)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "df_labelled[df_labelled.columns[:-1]] = scaler.fit_transform(df_labelled[df_labelled.columns[:-1]])\n",
    "df_unlabelled[df_unlabelled.columns] = scaler.transform(df_unlabelled[df_unlabelled.columns])\n",
    "df_except[df_except.columns[:-1]] = scaler.transform(df_except[df_except.columns[:-1]])\n",
    "\n",
    "# 划分有标签数据集的训练集和测试集\n",
    "X = df_labelled.drop(columns=['label'])\n",
    "y = df_labelled['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.99, random_state=42)\n",
    "\n",
    "# 使用训练集中所有的有标签数据\n",
    "X_train_labelled = X_train\n",
    "y_train_labelled = y_train\n",
    "\n",
    "# 无标签数据\n",
    "X_train_unlabelled = df_unlabelled\n",
    "\n",
    "# 处理后的df_except\n",
    "X_except = df_except.drop(columns=['label'])\n",
    "y_except = df_except['label']\n",
    "\n",
    "# 显示数据集状态\n",
    "print(f\"Labelled Data Shape: {df_labelled.shape}\")\n",
    "print(f\"Unlabelled Data Shape: {df_unlabelled.shape}\")\n",
    "print(f\"Except Data Shape: {df_except.shape}\")\n",
    "\n",
    "# 显示分割后数据集的形状\n",
    "print(f\"X_train Labelled Shape: {X_train_labelled.shape}\")\n",
    "print(f\"y_train Labelled Shape: {y_train_labelled.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")\n",
    "print(f\"X_except Shape: {X_except.shape}\")\n",
    "print(f\"y_except Shape: {y_except.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only found 0 labels for low confidence samples.\n",
      "Accuracy: 0.9959514170040485\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       172\n",
      "           1       1.00      1.00      1.00       816\n",
      "\n",
      "    accuracy                           1.00       988\n",
      "   macro avg       1.00      0.99      0.99       988\n",
      "weighted avg       1.00      1.00      1.00       988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 初始化XGBoost模型\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "# 半监督学习迭代\n",
    "max_iterations = 10\n",
    "confidence_threshold = 0.9\n",
    "low_confidence_sample_size = 100  # 定义一个合理的低置信度样本数量\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    # 使用模型预测无标签数据的概率\n",
    "    y_unlabelled_proba = clf.predict_proba(X_train_unlabelled)\n",
    "    \n",
    "    # 选择高置信度样本\n",
    "    high_confidence_indices = np.where(np.max(y_unlabelled_proba, axis=1) >= confidence_threshold)[0]\n",
    "    \n",
    "    if len(high_confidence_indices) == 0:\n",
    "        break\n",
    "    \n",
    "    X_high_confidence = X_train_unlabelled.iloc[high_confidence_indices]\n",
    "    y_high_confidence = np.argmax(y_unlabelled_proba[high_confidence_indices], axis=1)\n",
    "    \n",
    "    # 将高置信度样本添加到有标签的训练集中\n",
    "    X_train_labelled = pd.concat([X_train_labelled, X_high_confidence])\n",
    "    y_train_labelled = pd.concat([y_train_labelled, pd.Series(y_high_confidence)])\n",
    "    \n",
    "    # 从无标签数据集中删除高置信度样本\n",
    "    X_train_unlabelled = X_train_unlabelled.drop(X_high_confidence.index)\n",
    "    \n",
    "    # 主动学习部分\n",
    "    # 确保低置信度样本数量不超过未标记数据的大小\n",
    "    if len(X_train_unlabelled) < low_confidence_sample_size:\n",
    "        low_confidence_sample_size = len(X_train_unlabelled)\n",
    "    \n",
    "    # 重新计算未标记样本的预测概率\n",
    "    y_unlabelled_proba = clf.predict_proba(X_train_unlabelled)\n",
    "    \n",
    "    # 选择低置信度样本进行标注\n",
    "    low_confidence_indices = np.argsort(np.max(y_unlabelled_proba, axis=1))[:low_confidence_sample_size]\n",
    "    X_low_confidence = X_train_unlabelled.iloc[low_confidence_indices]\n",
    "    \n",
    "    # 从df_except中获取标签\n",
    "    X_low_confidence_features = X_low_confidence.reset_index(drop=True)\n",
    "    y_low_confidence_labels = df_except[df_except.drop(columns=['label']).apply(tuple, axis=1).isin(X_low_confidence_features.apply(tuple, axis=1))]['label'].values\n",
    "    \n",
    "    # 检查是否找到了所有低置信度样本的标签\n",
    "    if len(y_low_confidence_labels) < low_confidence_sample_size:\n",
    "        print(f\"Warning: Only found {len(y_low_confidence_labels)} labels for low confidence samples.\")\n",
    "        low_confidence_sample_size = len(y_low_confidence_labels)\n",
    "        X_low_confidence = X_low_confidence.iloc[:low_confidence_sample_size]\n",
    "    \n",
    "    # 添加低置信度样本及其标签到训练集中\n",
    "    X_train_labelled = pd.concat([X_train_labelled, X_low_confidence])\n",
    "    y_train_labelled = pd.concat([y_train_labelled, pd.Series(y_low_confidence_labels)])\n",
    "    \n",
    "    # 从无标签数据集中删除低置信度样本\n",
    "    X_train_unlabelled = X_train_unlabelled.drop(X_low_confidence.index)\n",
    "    \n",
    "    # 重新训练模型\n",
    "    clf.fit(X_train_labelled, y_train_labelled)\n",
    "\n",
    "# 模型评估\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
